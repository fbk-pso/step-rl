import os
import json
import itertools
import argparse
import importlib
import unified_planning as up
import unified_planning.io
from random import sample, seed

seed(0)

REPODIR = os.path.dirname(os.path.realpath(os.path.join(__file__, '..')))

QSUB_CMD = 'sbatch --job-name=rltool --mem=20000 --cpus-per-task=4 '

def generate_learning_json(path, problems_filter, config):
    """
    Generate files learning.json and planning.json from all possible combinations of parameters in learning_config and learning_planning_config
    """
    combinations_learning = generate_combinations(config['learning_config'])
    combinations_learning_planning = generate_combinations(config['learning_planning_config'])
    problems_config = config['problems_config']

    i = 0
    for comb_learning, comb_learning_planning in itertools.product(combinations_learning, combinations_learning_planning):
        i += 1
        os.makedirs(os.path.join(path, 'config_{}'.format(i)))
        output = comb_learning_planning
        with open(os.path.join(path, 'config_{}/planning.json'.format(i)), 'w') as outfile:
            json.dump(output, outfile, indent=2)
            outfile.write('\n')
        output = {**output, **comb_learning}
        output['problem_package'] = problems_config['problem_package']
        output['problem_class'] = problems_config['problem_class']
        output['problem_params'] = problems_config['problem_params']
        output['problem_filter'] = problems_filter
        with open(os.path.join(path, 'config_{}/learning.json'.format(i)), 'w') as outfile:
            json.dump(output, outfile, indent=2)
            outfile.write('\n')

    return i

def generate_combinations(learning_config):
    """
    Takes in input a dictionary of lists and returns an iterator of the dictionaries obtained by taking all possible combinations
    of the values in the lists
    """
    keys = learning_config.keys()
    values = learning_config.values()
    combinations = itertools.product(*values)
    confs = iter(dict(zip(keys, combination)) for combination in combinations)
    return confs

def generate_problem(domain, initial_values, objects, goals):
    problem = domain.clone()
    problem.all_objects.clear()
    problem.explicit_initial_values.clear()
    for o in objects:
        problem.add_object(o)
    for k, v in initial_values.items():
        problem.set_initial_value(k, v)
    for g in goals:
        problem.add_goal(g)
    return problem

def generate_instances_sets(path, problems_config):
    """
    If the parameter k-fold_cross-validation is True, training sets and testing sets are generated by k-fold cross-validation.
    Otherwise the training set is the whole problem set and the testing set is the same as the training set.
    """
    module = importlib.import_module(problems_config['problem_package'])
    problem_params = [tuple(p) if type(p)==list else p for p in problems_config['problem_params']]
    problem_generator = getattr(module, problems_config['problem_class'])(*problem_params)
    n_problems = problem_generator.size()
    domain = problem_generator.domain()
    print(f"Number of problems : {n_problems}")

    w = up.io.ANMLWriter(domain)
    w.write_problem(os.path.join(path, '..', 'domain.anml'))

    if problems_config['k-fold_cross-validation']:
        k = problems_config['k']
        all = list(range(n_problems))
        tmp = []
        tmp.extend(all)
        for i in range(1, k+1):
            test = sample(tmp, int(len(all)/k))
            train = list(set(all) - set(test))
            tmp = list(set(tmp) - set(test))
            os.makedirs(os.path.join(path, 'set_{}'.format(i)))
            with open(os.path.join(path, 'set_{}'.format(i), 'training_set.txt'), 'w') as outfile:
                for f in train:
                    outfile.write(str(f)+'\n')
            os.makedirs(os.path.join(path, 'set_{}'.format(i), 'testing_set'))
            for j, (initial_values, objects, goals) in enumerate(problem_generator.get_problems()):
                if j not in test:
                    continue
                problem = generate_problem(domain, initial_values, objects, goals)
                w = up.io.ANMLWriter(problem)
                w.write_problem(os.path.join(path, 'set_{}'.format(i), 'testing_set', 'problem_{}.anml'.format(j)))

    else:
        k = 1
        os.makedirs(os.path.join(path, 'set_1'))
        with open(os.path.join(path, 'set_1/training_set.txt'), 'w') as outfile:
            for f in range(n_problems):
                outfile.write(str(f)+'\n')
        os.makedirs(os.path.join(path, 'set_1', 'testing_set'))
        for j, (initial_values, objects, goals) in enumerate(problem_generator.get_problems()):
            problem = generate_problem(domain, initial_values, objects, goals)
            w = up.io.ANMLWriter(problem)
            w.write_problem(os.path.join(path, 'set_1', 'testing_set', 'problem_{}.anml'.format(j)))
    return k


def generate_run(config_file, output_file, cluster, slurm_args):
    """
    Reads the file configurations.json inside an experiment folder and prepares all files necessary for the learning phase.
    In particular it generates the directory structure for the experiment, the datasets of problems and the file run_learning.sh.
    There are three levels of nesting in the directory tree, from outermost to innermost:
    1) instance set (by cross-validation)
    2) configuration (by all possible combinations of parameters in the config file)
    3) run (by varying the random seed)

    :param config_file: input json file
    :param output_file: bash script to be created (run_learning.sh by default) which will execute main.py
    :param cluster: a boolean specifying if the experiment is to be run in local or on cluster with slurm
    """

    with open(config_file) as json_file:
        path = os.path.dirname(os.path.abspath(config_file))
        config = json.load(json_file)

        problems_config = config['problems_config']
        path = os.path.join(path, 'instances_sets')
        os.makedirs(path)
        k = generate_instances_sets(path, problems_config)

        for i in range(1, k+1):
            n_configs = generate_learning_json(os.path.join(path, 'set_{}'.format(i), 'learning_configurations'),
                                               os.path.join(path, 'set_{}'.format(i), 'training_set.txt'),
                                               config)
        n_runs = config['runs']
        CMD = os.path.join(REPODIR, 'main.py')
        if cluster:
            QSUB_FULL_CMD = QSUB_CMD + ' '.join(slurm_args)
        with open(output_file, 'w') as output:
            for s in range(1, k+1):
                for c in range(1, n_configs+1):
                    learning = os.path.join(path, 'set_{}'.format(s), 'learning_configurations',
                                            'config_{}'.format(c), 'learning.json')
                    for r in range(1, n_runs+1):
                        run_dir = os.path.join(path, 'set_{}'.format(s), 'learning_configurations',
                                               'config_{}'.format(c), 'runs', 'run_{}'.format(r))
                        os.makedirs(run_dir)
                        os.makedirs(os.path.join(run_dir, 'models'))
                        if cluster:
                            FULL_CMD = QSUB_FULL_CMD + ' --output=' + os.path.join(run_dir, 'slurm-%j.out') + ' ' + CMD
                        else:
                            FULL_CMD = CMD
                        output.write(FULL_CMD+' -f '+learning+' -o '+run_dir+' learn\n')



def main():
    parser = argparse.ArgumentParser(add_help=False)
    parser.add_argument('-i', required=True, type=str)
    parser.add_argument('-c', action='store_true')

    args, slurm_args = parser.parse_known_args()

    generate_run(os.path.join(args.i, 'configurations.json'),
                 os.path.join(args.i, 'run_learning.sh'),
                 args.c,
                 slurm_args)


if __name__ == '__main__':
    main()
